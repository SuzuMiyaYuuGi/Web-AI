import json
from ollama_utils import ask_llama
from pythainlp.tokenize import word_tokenize
from sklearn.feature_extraction.text import TfidfVectorizer

# Load data from JSON
with open("output_data.json", encoding="utf-8") as f:
    docs = json.load(f)

# Improved Token Matching: Lemmatization or stemming (if applicable for Thai language)
def tokenize_and_clean(question):
    # Example: could implement stemming or lemmatization here (e.g., using pythainlp's stem function)
    return word_tokenize(question.lower(), engine='newmm')

# Use TF-IDF for more context-aware document retrieval
def find_best_context(question: str):
    question_words = tokenize_and_clean(question)
    
    # Build the document corpus including HTML and metadata text for TF-IDF
    corpus = [entry.get("HTML", "") + " " + entry.get("Header", "") + " " + entry.get("Tag", "") for entry in docs]
    
    # Convert to TF-IDF vectors
    vectorizer = TfidfVectorizer(stop_words="english")
    tfidf_matrix = vectorizer.fit_transform(corpus)
    
    # Vectorize the question
    question_vec = vectorizer.transform([" ".join(question_words)])

    # Compute cosine similarity between question and each document
    similarities = tfidf_matrix * question_vec.T
    scores = similarities.toarray().flatten()

    # Get the best matching document based on similarity score
    best_match_idx = scores.argmax()
    if scores[best_match_idx] == 0:
        return None

    return docs[best_match_idx]

# Combine metadata into the context to enhance response generation
def build_prompt(question: str, context_html: str, metadata: dict):
    base = """
‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á
‡∏ô‡∏≥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏°‡∏≤‡∏ï‡∏≠‡∏ö‡πÄ‡∏•‡∏¢‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢

‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î:
- ‡∏ï‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
- ‡∏´‡∏≤‡∏Å‡∏™‡∏£‡∏∏‡∏õ ‡πÉ‡∏´‡πâ‡∏™‡∏±‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡πÅ‡∏ï‡πà‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô
"""
    meta = f"""[‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö]: {metadata.get("NamePage", "")}
[‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà/‡∏®‡∏π‡∏ô‡∏¢‡πå]: {metadata.get("Center", "")}
[‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠]: {metadata.get("Header", "")}
[‡πÅ‡∏ó‡πá‡∏Å]: {metadata.get("Tag", "")}"""

    return f"""{base}

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:
{question}

‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå:
{meta}

[HTML ‡∏Ç‡∏≠‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå]:
{context_html}

‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:
"""

# Function to answer the question based on the context
def answer_question(question: str):
    context = find_best_context(question)
    if not context:
        return "‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"

    html_content = context.get("HTML", "")[:10000]  # Limit content to the first 10,000 characters
    prompt = build_prompt(question, html_content, context)
    reply = ask_llama(prompt)

    return f"{reply.strip()}\n\nüîó ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á: {context.get('URL', '‡πÑ‡∏°‡πà‡∏û‡∏ö URL')}"
