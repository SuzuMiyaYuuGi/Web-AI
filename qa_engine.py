import json
import difflib
from pythainlp.tokenize import word_tokenize
from ollama_utils import ask_llama

# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå JSON ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏î‡∏∂‡∏á‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå
with open("output_data.json", encoding="utf-8") as f:
    docs = json.load(f)

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡πÉ‡∏ä‡πâ PyThaiNLP ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏≥
def preprocess_question(question: str):
    # ‡πÉ‡∏ä‡πâ PyThaiNLP ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏≥
    tokenized_words = word_tokenize(question)
    return tokenized_words

# ‡πÉ‡∏ä‡πâ HTML ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤ field ‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏£‡∏≠‡∏á‡∏•‡∏á‡∏°‡∏≤
def find_best_context(question: str):
    question_words = preprocess_question(question)  # ‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏≥‡∏Å‡πà‡∏≠‡∏ô‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
    scored = []

    for entry in docs:
        html_text = entry.get("HTML", "").lower()
        other_text = " ".join([
            entry.get("Header", ""),
            entry.get("Tag", ""),
            entry.get("NamePage", ""),
            entry.get("Center", "")
        ]).lower()

        html_score = sum(word in html_text for word in question_words) * 3
        other_score = sum(word in other_text for word in question_words) * 1
        total_score = html_score + other_score

        if total_score > 0:
            scored.append((total_score, entry))

    if not scored:
        return None

    scored.sort(reverse=True, key=lambda x: x[0])
    return scored[0][1]

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏™‡∏∞‡∏Å‡∏î‡∏ú‡∏¥‡∏î
def correct_spelling(question: str, keywords: list):
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ú‡∏¥‡∏î‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ difflib"""
    corrected_question = question
    for word in keywords:
        # ‡πÉ‡∏ä‡πâ difflib ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô
        closest_match = difflib.get_close_matches(word, question.split(), n=1, cutoff=0.8)
        if closest_match:
            corrected_question = corrected_question.replace(closest_match[0], word)
    return corrected_question

# ‡∏£‡∏ß‡∏° metadata ‡πÄ‡∏Ç‡πâ‡∏≤ context + ‡πÉ‡∏´‡πâ LLM ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÄ‡∏≠‡∏á (‡πÅ‡∏ó‡∏ô intent)
def build_prompt(question: str, context_html: str, metadata: dict):
    base = """
‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á
‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡∏ô‡∏µ‡πâ"

‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡πÄ‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡πÄ‡∏ä‡πà‡∏ô:
- ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö "‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏ô‡πâ‡∏≤‡πÑ‡∏´‡∏ô / ‡∏•‡∏¥‡∏á‡∏Å‡πå / ‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô" ‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏∏ URL ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
- ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ß‡πà‡∏≤ "‡∏°‡∏µ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£/‡∏°‡∏µ‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÑ‡∏´‡∏°" ‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ URL ‡∏ñ‡πâ‡∏≤‡∏û‡∏ö
- ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡πÉ‡∏´‡πâ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡πÅ‡∏ö‡∏ö‡∏™‡∏±‡πâ‡∏ô ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢

‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î:
- ‡∏ï‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
- ‡∏´‡∏≤‡∏Å‡∏™‡∏£‡∏∏‡∏õ ‡πÉ‡∏´‡πâ‡∏™‡∏±‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
"""
    meta = f"""[‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö]: {metadata.get("NamePage", "")}
[‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà/‡∏®‡∏π‡∏ô‡∏¢‡πå]: {metadata.get("Center", "")}
[‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠]: {metadata.get("Header", "")}
[‡πÅ‡∏ó‡πá‡∏Å]: {metadata.get("Tag", "")}"""

    return f"""{base}

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:
{question}

‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå:
{meta}

[HTML ‡∏Ç‡∏≠‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå]:
{context_html}

‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:
"""

def answer_question(question: str):
    # ‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏≥‡∏Ñ‡∏µ‡∏¢‡πå‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏î‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
    question_words = question.lower().split()

    # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
    context = find_best_context(question)
    if not context:
        return "‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏™‡∏∞‡∏Å‡∏î‡∏ú‡∏¥‡∏î
    corrected_question = correct_spelling(question, question_words)

    # ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
    context = find_best_context(corrected_question)
    if not context:
        return "‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"

    html_content = context.get("HTML", "")[:10000]
    prompt = build_prompt(corrected_question, html_content, context)
    reply = ask_llama(prompt)

    return f"{reply.strip()}\n\nüîó ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á: {context.get('URL', '‡πÑ‡∏°‡πà‡∏û‡∏ö URL')}"
